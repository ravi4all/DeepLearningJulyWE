{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\asus\\AppData\\Local\\Temp\\tmp3j_j27_t\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_num_ps_replicas': 0, '_evaluation_master': '', '_task_type': None, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000225999DD358>, '_is_chief': True, '_num_worker_replicas': 0, '_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_model_dir': 'C:\\\\Users\\\\asus\\\\AppData\\\\Local\\\\Temp\\\\tmp3j_j27_t', '_task_id': 0, '_master': '', '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.contrib.learn.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)\n",
    "# model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\asus\\AppData\\Local\\Temp\\tmp3j_j27_t\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 4.74811e+10\n",
      "INFO:tensorflow:global_step/sec: 321.068\n",
      "INFO:tensorflow:step = 101, loss = 4.64502e+10 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.087\n",
      "INFO:tensorflow:step = 201, loss = 3.31106e+10 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.491\n",
      "INFO:tensorflow:step = 301, loss = 5.50451e+10 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.513\n",
      "INFO:tensorflow:step = 401, loss = 8.40013e+10 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.197\n",
      "INFO:tensorflow:step = 501, loss = 6.37039e+10 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.651\n",
      "INFO:tensorflow:step = 601, loss = 1.85653e+10 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.87\n",
      "INFO:tensorflow:step = 701, loss = 4.16187e+10 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.261\n",
      "INFO:tensorflow:step = 801, loss = 1.64442e+10 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.611\n",
      "INFO:tensorflow:step = 901, loss = 2.33954e+10 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:step = 1001, loss = 1.7553e+10 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.608\n",
      "INFO:tensorflow:step = 1101, loss = 3.8642e+10 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.158\n",
      "INFO:tensorflow:step = 1201, loss = 5.23926e+09 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.416\n",
      "INFO:tensorflow:step = 1301, loss = 7.16551e+09 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.313\n",
      "INFO:tensorflow:step = 1401, loss = 7.27496e+09 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.1\n",
      "INFO:tensorflow:step = 1501, loss = 3.9194e+09 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.278\n",
      "INFO:tensorflow:step = 1601, loss = 1.9302e+10 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.033\n",
      "INFO:tensorflow:step = 1701, loss = 1.59578e+10 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.564\n",
      "INFO:tensorflow:step = 1801, loss = 7.43477e+09 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.721\n",
      "INFO:tensorflow:step = 1901, loss = 1.90418e+09 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.723\n",
      "INFO:tensorflow:step = 2001, loss = 3.89169e+09 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.795\n",
      "INFO:tensorflow:step = 2101, loss = 9.52992e+09 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.064\n",
      "INFO:tensorflow:step = 2201, loss = 8.32991e+09 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.566\n",
      "INFO:tensorflow:step = 2301, loss = 7.61286e+09 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.957\n",
      "INFO:tensorflow:step = 2401, loss = 1.07219e+10 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.796\n",
      "INFO:tensorflow:step = 2501, loss = 8.25099e+09 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.607\n",
      "INFO:tensorflow:step = 2601, loss = 1.94037e+10 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.972\n",
      "INFO:tensorflow:step = 2701, loss = 1.86943e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.358\n",
      "INFO:tensorflow:step = 2801, loss = 9.25173e+09 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.976\n",
      "INFO:tensorflow:step = 2901, loss = 9.88873e+09 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.939\n",
      "INFO:tensorflow:step = 3001, loss = 1.90838e+10 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.393\n",
      "INFO:tensorflow:step = 3101, loss = 1.11814e+10 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.619\n",
      "INFO:tensorflow:step = 3201, loss = 4.55426e+09 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.237\n",
      "INFO:tensorflow:step = 3301, loss = 8.71041e+09 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:step = 3401, loss = 1.4658e+10 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.583\n",
      "INFO:tensorflow:step = 3501, loss = 1.2378e+10 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.707\n",
      "INFO:tensorflow:step = 3601, loss = 2.32686e+10 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.922\n",
      "INFO:tensorflow:step = 3701, loss = 4.60115e+09 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.883\n",
      "INFO:tensorflow:step = 3801, loss = 1.82847e+10 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.2\n",
      "INFO:tensorflow:step = 3901, loss = 7.90645e+09 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.454\n",
      "INFO:tensorflow:step = 4001, loss = 6.76673e+09 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.059\n",
      "INFO:tensorflow:step = 4101, loss = 1.98991e+10 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.444\n",
      "INFO:tensorflow:step = 4201, loss = 5.29724e+09 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.455\n",
      "INFO:tensorflow:step = 4301, loss = 1.13544e+10 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.209\n",
      "INFO:tensorflow:step = 4401, loss = 6.28405e+09 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.295\n",
      "INFO:tensorflow:step = 4501, loss = 3.30104e+09 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.707\n",
      "INFO:tensorflow:step = 4601, loss = 7.17134e+09 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.489\n",
      "INFO:tensorflow:step = 4701, loss = 3.98751e+09 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.568\n",
      "INFO:tensorflow:step = 4801, loss = 1.2242e+10 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.995\n",
      "INFO:tensorflow:step = 4901, loss = 7.20896e+09 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.717\n",
      "INFO:tensorflow:step = 5001, loss = 1.02364e+10 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.664\n",
      "INFO:tensorflow:step = 5101, loss = 8.44534e+09 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.172\n",
      "INFO:tensorflow:step = 5201, loss = 4.41934e+09 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.717\n",
      "INFO:tensorflow:step = 5301, loss = 3.0111e+09 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.745\n",
      "INFO:tensorflow:step = 5401, loss = 7.89731e+09 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.743\n",
      "INFO:tensorflow:step = 5501, loss = 1.11187e+10 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.762\n",
      "INFO:tensorflow:step = 5601, loss = 8.64842e+09 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.989\n",
      "INFO:tensorflow:step = 5701, loss = 4.50201e+09 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.717\n",
      "INFO:tensorflow:step = 5801, loss = 1.47804e+10 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.063\n",
      "INFO:tensorflow:step = 5901, loss = 1.27895e+10 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.477\n",
      "INFO:tensorflow:step = 6001, loss = 5.60125e+09 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.95\n",
      "INFO:tensorflow:step = 6101, loss = 1.0749e+10 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.659\n",
      "INFO:tensorflow:step = 6201, loss = 5.61328e+09 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.843\n",
      "INFO:tensorflow:step = 6301, loss = 7.57782e+09 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.294\n",
      "INFO:tensorflow:step = 6401, loss = 1.41579e+10 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.567\n",
      "INFO:tensorflow:step = 6501, loss = 1.1144e+10 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.206\n",
      "INFO:tensorflow:step = 6601, loss = 9.71342e+09 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.812\n",
      "INFO:tensorflow:step = 6701, loss = 1.09857e+10 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.412\n",
      "INFO:tensorflow:step = 6801, loss = 1.88806e+10 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.551\n",
      "INFO:tensorflow:step = 6901, loss = 4.72909e+09 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.457\n",
      "INFO:tensorflow:step = 7001, loss = 1.61325e+10 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.551\n",
      "INFO:tensorflow:step = 7101, loss = 1.01072e+10 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.667\n",
      "INFO:tensorflow:step = 7201, loss = 7.95621e+09 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.023\n",
      "INFO:tensorflow:step = 7301, loss = 1.30948e+10 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.381\n",
      "INFO:tensorflow:step = 7401, loss = 8.09585e+09 (0.278 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 355.579\n",
      "INFO:tensorflow:step = 7501, loss = 1.35365e+10 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.384\n",
      "INFO:tensorflow:step = 7601, loss = 1.5071e+10 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.552\n",
      "INFO:tensorflow:step = 7701, loss = 5.65676e+09 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.986\n",
      "INFO:tensorflow:step = 7801, loss = 6.90869e+09 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.665\n",
      "INFO:tensorflow:step = 7901, loss = 1.74628e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.214\n",
      "INFO:tensorflow:step = 8001, loss = 7.64263e+09 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.881\n",
      "INFO:tensorflow:step = 8101, loss = 1.13467e+10 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.012\n",
      "INFO:tensorflow:step = 8201, loss = 8.11516e+09 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.999\n",
      "INFO:tensorflow:step = 8301, loss = 1.11403e+10 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.515\n",
      "INFO:tensorflow:step = 8401, loss = 1.36739e+10 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.063\n",
      "INFO:tensorflow:step = 8501, loss = 1.79031e+10 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.234\n",
      "INFO:tensorflow:step = 8601, loss = 1.18467e+10 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.142\n",
      "INFO:tensorflow:step = 8701, loss = 2.24913e+10 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.553\n",
      "INFO:tensorflow:step = 8801, loss = 9.69613e+09 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.276\n",
      "INFO:tensorflow:step = 8901, loss = 1.58624e+10 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.145\n",
      "INFO:tensorflow:step = 9001, loss = 1.48721e+10 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.616\n",
      "INFO:tensorflow:step = 9101, loss = 1.17276e+10 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.065\n",
      "INFO:tensorflow:step = 9201, loss = 6.77062e+09 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.88\n",
      "INFO:tensorflow:step = 9301, loss = 5.22273e+09 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.763\n",
      "INFO:tensorflow:step = 9401, loss = 1.4877e+10 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.491\n",
      "INFO:tensorflow:step = 9501, loss = 9.08104e+09 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.707\n",
      "INFO:tensorflow:step = 9601, loss = 8.94434e+09 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.718\n",
      "INFO:tensorflow:step = 9701, loss = 3.36954e+09 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.008\n",
      "INFO:tensorflow:step = 9801, loss = 6.67978e+09 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.053\n",
      "INFO:tensorflow:step = 9901, loss = 1.43033e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.96\n",
      "INFO:tensorflow:step = 10001, loss = 1.09294e+10 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.228\n",
      "INFO:tensorflow:step = 10101, loss = 8.49661e+09 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.02\n",
      "INFO:tensorflow:step = 10201, loss = 4.27539e+09 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.469\n",
      "INFO:tensorflow:step = 10301, loss = 6.57143e+09 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.415\n",
      "INFO:tensorflow:step = 10401, loss = 9.7228e+09 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.182\n",
      "INFO:tensorflow:step = 10501, loss = 1.22901e+10 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.937\n",
      "INFO:tensorflow:step = 10601, loss = 1.52927e+10 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.297\n",
      "INFO:tensorflow:step = 10701, loss = 6.78491e+09 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.02\n",
      "INFO:tensorflow:step = 10801, loss = 1.69294e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.429\n",
      "INFO:tensorflow:step = 10901, loss = 1.37723e+10 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.019\n",
      "INFO:tensorflow:step = 11001, loss = 8.48481e+09 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.513\n",
      "INFO:tensorflow:step = 11101, loss = 1.83437e+10 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.585\n",
      "INFO:tensorflow:step = 11201, loss = 2.81145e+09 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.938\n",
      "INFO:tensorflow:step = 11301, loss = 9.06194e+09 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.26\n",
      "INFO:tensorflow:step = 11401, loss = 8.22576e+09 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.806\n",
      "INFO:tensorflow:step = 11501, loss = 1.26111e+10 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.943\n",
      "INFO:tensorflow:step = 11601, loss = 7.37745e+09 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.406\n",
      "INFO:tensorflow:step = 11701, loss = 9.9984e+09 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:step = 11801, loss = 4.92176e+09 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.277\n",
      "INFO:tensorflow:step = 11901, loss = 1.48674e+10 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.58\n",
      "INFO:tensorflow:step = 12001, loss = 9.54091e+09 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.32\n",
      "INFO:tensorflow:step = 12101, loss = 5.09202e+09 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.513\n",
      "INFO:tensorflow:step = 12201, loss = 8.09329e+09 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.223\n",
      "INFO:tensorflow:step = 12301, loss = 7.84506e+09 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.54\n",
      "INFO:tensorflow:step = 12401, loss = 7.53852e+09 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.497\n",
      "INFO:tensorflow:step = 12501, loss = 6.05354e+09 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.424\n",
      "INFO:tensorflow:step = 12601, loss = 1.12418e+10 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.402\n",
      "INFO:tensorflow:step = 12701, loss = 6.61118e+09 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.581\n",
      "INFO:tensorflow:step = 12801, loss = 1.13895e+10 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.258\n",
      "INFO:tensorflow:step = 12901, loss = 2.71727e+09 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.82\n",
      "INFO:tensorflow:step = 13001, loss = 9.02754e+09 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.471\n",
      "INFO:tensorflow:step = 13101, loss = 3.06522e+09 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.536\n",
      "INFO:tensorflow:step = 13201, loss = 5.75635e+09 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.368\n",
      "INFO:tensorflow:step = 13301, loss = 1.54642e+10 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.667\n",
      "INFO:tensorflow:step = 13401, loss = 7.55122e+09 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.345\n",
      "INFO:tensorflow:step = 13501, loss = 2.11777e+09 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.008\n",
      "INFO:tensorflow:step = 13601, loss = 1.18873e+10 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.36\n",
      "INFO:tensorflow:step = 13701, loss = 1.04067e+10 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.638\n",
      "INFO:tensorflow:step = 13801, loss = 5.84771e+09 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.845\n",
      "INFO:tensorflow:step = 13901, loss = 7.70147e+09 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.011\n",
      "INFO:tensorflow:step = 14001, loss = 1.14093e+10 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.001\n",
      "INFO:tensorflow:step = 14101, loss = 8.99201e+09 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.416\n",
      "INFO:tensorflow:step = 14201, loss = 1.49598e+10 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.609\n",
      "INFO:tensorflow:step = 14301, loss = 3.54203e+09 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.463\n",
      "INFO:tensorflow:step = 14401, loss = 2.11372e+10 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.685\n",
      "INFO:tensorflow:step = 14501, loss = 4.07962e+09 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.558\n",
      "INFO:tensorflow:step = 14601, loss = 8.86496e+09 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.665\n",
      "INFO:tensorflow:step = 14701, loss = 1.11198e+10 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.575\n",
      "INFO:tensorflow:step = 14801, loss = 1.16644e+10 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.711\n",
      "INFO:tensorflow:step = 14901, loss = 1.32042e+10 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.53\n",
      "INFO:tensorflow:step = 15001, loss = 8.47277e+09 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.973\n",
      "INFO:tensorflow:step = 15101, loss = 2.02154e+10 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.566\n",
      "INFO:tensorflow:step = 15201, loss = 4.42322e+09 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.766\n",
      "INFO:tensorflow:step = 15301, loss = 1.19905e+10 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.096\n",
      "INFO:tensorflow:step = 15401, loss = 1.08506e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.295\n",
      "INFO:tensorflow:step = 15501, loss = 8.26064e+09 (0.309 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 322.58\n",
      "INFO:tensorflow:step = 15601, loss = 1.25983e+10 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.092\n",
      "INFO:tensorflow:step = 15701, loss = 1.75052e+10 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.175\n",
      "INFO:tensorflow:step = 15801, loss = 6.59659e+09 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.873\n",
      "INFO:tensorflow:step = 15901, loss = 1.14775e+10 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.806\n",
      "INFO:tensorflow:step = 16001, loss = 1.47489e+10 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.893\n",
      "INFO:tensorflow:step = 16101, loss = 4.17067e+09 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.511\n",
      "INFO:tensorflow:step = 16201, loss = 1.38122e+10 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.927\n",
      "INFO:tensorflow:step = 16301, loss = 1.12102e+10 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.364\n",
      "INFO:tensorflow:step = 16401, loss = 1.29888e+10 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.395\n",
      "INFO:tensorflow:step = 16501, loss = 1.17025e+10 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.105\n",
      "INFO:tensorflow:step = 16601, loss = 4.50025e+09 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.468\n",
      "INFO:tensorflow:step = 16701, loss = 5.08822e+09 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.764\n",
      "INFO:tensorflow:step = 16801, loss = 9.4097e+09 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.802\n",
      "INFO:tensorflow:step = 16901, loss = 7.20668e+09 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.755\n",
      "INFO:tensorflow:step = 17001, loss = 4.11803e+09 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.969\n",
      "INFO:tensorflow:step = 17101, loss = 5.24007e+09 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.655\n",
      "INFO:tensorflow:step = 17201, loss = 5.44829e+09 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.995\n",
      "INFO:tensorflow:step = 17301, loss = 9.60074e+09 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.17\n",
      "INFO:tensorflow:step = 17401, loss = 1.64172e+10 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.732\n",
      "INFO:tensorflow:step = 17501, loss = 3.4299e+09 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.022\n",
      "INFO:tensorflow:step = 17601, loss = 1.23218e+10 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.462\n",
      "INFO:tensorflow:step = 17701, loss = 1.31133e+10 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.753\n",
      "INFO:tensorflow:step = 17801, loss = 4.73282e+09 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.553\n",
      "INFO:tensorflow:step = 17901, loss = 5.33699e+09 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.172\n",
      "INFO:tensorflow:step = 18001, loss = 8.84108e+09 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.841\n",
      "INFO:tensorflow:step = 18101, loss = 8.00764e+09 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.11\n",
      "INFO:tensorflow:step = 18201, loss = 7.00742e+09 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.869\n",
      "INFO:tensorflow:step = 18301, loss = 1.23278e+10 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.834\n",
      "INFO:tensorflow:step = 18401, loss = 5.49835e+09 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.525\n",
      "INFO:tensorflow:step = 18501, loss = 1.98911e+10 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.234\n",
      "INFO:tensorflow:step = 18601, loss = 5.20797e+09 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.938\n",
      "INFO:tensorflow:step = 18701, loss = 1.41597e+10 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.049\n",
      "INFO:tensorflow:step = 18801, loss = 5.05799e+09 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.209\n",
      "INFO:tensorflow:step = 18901, loss = 7.36336e+09 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.937\n",
      "INFO:tensorflow:step = 19001, loss = 1.42947e+10 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.356\n",
      "INFO:tensorflow:step = 19101, loss = 2.50211e+09 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.162\n",
      "INFO:tensorflow:step = 19201, loss = 1.23991e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.906\n",
      "INFO:tensorflow:step = 19301, loss = 1.20378e+10 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.919\n",
      "INFO:tensorflow:step = 19401, loss = 8.21211e+09 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.183\n",
      "INFO:tensorflow:step = 19501, loss = 2.57808e+09 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.147\n",
      "INFO:tensorflow:step = 19601, loss = 3.27205e+09 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.951\n",
      "INFO:tensorflow:step = 19701, loss = 1.49089e+10 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.667\n",
      "INFO:tensorflow:step = 19801, loss = 7.55963e+09 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.027\n",
      "INFO:tensorflow:step = 19901, loss = 1.12303e+10 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.021\n",
      "INFO:tensorflow:step = 20001, loss = 6.22124e+09 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.178\n",
      "INFO:tensorflow:step = 20101, loss = 9.30454e+09 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.566\n",
      "INFO:tensorflow:step = 20201, loss = 9.59222e+09 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.636\n",
      "INFO:tensorflow:step = 20301, loss = 3.22656e+09 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.138\n",
      "INFO:tensorflow:step = 20401, loss = 8.79348e+09 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.021\n",
      "INFO:tensorflow:step = 20501, loss = 4.23528e+09 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.576\n",
      "INFO:tensorflow:step = 20601, loss = 1.11912e+10 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.708\n",
      "INFO:tensorflow:step = 20701, loss = 1.27263e+10 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.609\n",
      "INFO:tensorflow:step = 20801, loss = 6.44553e+09 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.18\n",
      "INFO:tensorflow:step = 20901, loss = 1.31227e+10 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.729\n",
      "INFO:tensorflow:step = 21001, loss = 8.68869e+09 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.097\n",
      "INFO:tensorflow:step = 21101, loss = 1.06723e+10 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.447\n",
      "INFO:tensorflow:step = 21201, loss = 7.42859e+09 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.154\n",
      "INFO:tensorflow:step = 21301, loss = 9.9785e+09 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.716\n",
      "INFO:tensorflow:step = 21401, loss = 3.29552e+09 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.207\n",
      "INFO:tensorflow:step = 21501, loss = 1.86351e+10 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.139\n",
      "INFO:tensorflow:step = 21601, loss = 6.83976e+09 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.578\n",
      "INFO:tensorflow:step = 21701, loss = 7.3776e+09 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.047\n",
      "INFO:tensorflow:step = 21801, loss = 1.24667e+10 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.14\n",
      "INFO:tensorflow:step = 21901, loss = 1.21994e+10 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.578\n",
      "INFO:tensorflow:step = 22001, loss = 2.60818e+10 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.893\n",
      "INFO:tensorflow:step = 22101, loss = 1.48172e+10 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.694\n",
      "INFO:tensorflow:step = 22201, loss = 1.80745e+10 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.462\n",
      "INFO:tensorflow:step = 22301, loss = 7.24439e+09 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:step = 22401, loss = 4.60353e+09 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.932\n",
      "INFO:tensorflow:step = 22501, loss = 9.04333e+09 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.313\n",
      "INFO:tensorflow:step = 22601, loss = 7.04612e+09 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.432\n",
      "INFO:tensorflow:step = 22701, loss = 4.50022e+09 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.578\n",
      "INFO:tensorflow:step = 22801, loss = 8.99518e+09 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.921\n",
      "INFO:tensorflow:step = 22901, loss = 3.0124e+09 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.838\n",
      "INFO:tensorflow:step = 23001, loss = 6.69775e+09 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.613\n",
      "INFO:tensorflow:step = 23101, loss = 1.09357e+10 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.493\n",
      "INFO:tensorflow:step = 23201, loss = 7.1385e+09 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.052\n",
      "INFO:tensorflow:step = 23301, loss = 1.10207e+10 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.613\n",
      "INFO:tensorflow:step = 23401, loss = 1.05445e+10 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.297\n",
      "INFO:tensorflow:step = 23501, loss = 3.29825e+09 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.359\n",
      "INFO:tensorflow:step = 23601, loss = 4.58525e+09 (0.300 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 316.008\n",
      "INFO:tensorflow:step = 23701, loss = 1.59078e+10 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.716\n",
      "INFO:tensorflow:step = 23801, loss = 9.85984e+09 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.066\n",
      "INFO:tensorflow:step = 23901, loss = 7.0714e+09 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.192\n",
      "INFO:tensorflow:step = 24001, loss = 7.72781e+09 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.616\n",
      "INFO:tensorflow:step = 24101, loss = 3.21969e+09 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.049\n",
      "INFO:tensorflow:step = 24201, loss = 1.2307e+10 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.05\n",
      "INFO:tensorflow:step = 24301, loss = 8.30207e+09 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.239\n",
      "INFO:tensorflow:step = 24401, loss = 6.92505e+09 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.738\n",
      "INFO:tensorflow:step = 24501, loss = 2.45113e+09 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.432\n",
      "INFO:tensorflow:step = 24601, loss = 1.10761e+10 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.193\n",
      "INFO:tensorflow:step = 24701, loss = 7.93679e+09 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.233\n",
      "INFO:tensorflow:step = 24801, loss = 8.43602e+09 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.548\n",
      "INFO:tensorflow:step = 24901, loss = 4.73387e+09 (0.314 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\asus\\AppData\\Local\\Temp\\tmp3j_j27_t\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.5511e+09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'embedding_lr_multipliers': None, 'gradient_clip_norm': None, 'input_layer_min_slice_size': None, 'feature_columns': (_NumericColumn(key='housingMedianAge', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='totalRooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='totalBedrooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='population', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='households', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='medianIncome', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)), 'activation_fn': <function relu at 0x000002259D4AB7B8>, 'optimizer': None, 'hidden_units': [6, 6, 6], 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x00000225999DD9E8>, 'dropout': None})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:347: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:744: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3d4562656428>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_input_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m               instructions)\n\u001b[1;32m--> 347\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    349\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m               instructions)\n\u001b[1;32m--> 347\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    349\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[0;32m    706\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m           as_iterable=as_iterable)\n\u001b[0m\u001b[0;32m    709\u001b[0m     return super(DNNRegressor, self).predict(\n\u001b[0;32m    710\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m               instructions)\n\u001b[1;32m--> 347\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    349\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\u001b[0m in \u001b[0;36mpredict_scores\u001b[1;34m(self, x, input_fn, batch_size, as_iterable)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         as_iterable=as_iterable)\n\u001b[0m\u001b[0;32m    745\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             instructions)\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[0;32m    583\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mSKCompat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     return self._infer_model(\n\u001b[0;32m    587\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_get_input_fn\u001b[1;34m(x, y, input_fn, feed_fn, batch_size, shuffle, epochs)\u001b[0m\n\u001b[0;32m    135\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m       epochs=epochs)\n\u001b[0m\u001b[0;32m    138\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_builder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feed_dict_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py\u001b[0m in \u001b[0;36msetup_train_data_feeder\u001b[1;34m(x, y, n_classes, batch_size, shuffle, epochs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mStreamingDataFeeder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m   return data_feeder_cls(\n\u001b[1;32m--> 152\u001b[1;33m       x, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, n_classes, batch_size, shuffle, random_state, epochs)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m     self._x = dict([(k, check_array(v, v.dtype)) for k, v in list(x.items())\n\u001b[1;32m--> 324\u001b[1;33m                    ]) if x_is_dict else check_array(x, x.dtype)\n\u001b[0m\u001b[0;32m    325\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m       \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx_is_dict\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Marcial\\AppData\\Local\\Temp\\tmp244d0d44\\model.ckpt-25000\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97921.93181985477"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
